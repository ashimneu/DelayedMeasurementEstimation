For the purpose of comparing algorithms, it is convenient to introduce the vectors 
 $\Boldb_y = [b_{y_1},b_{y_2}, .. ,b_{y_m}]^\top$,
 $\Boldb_x = [b_{x_1},b_{x_2}, .. ,b_{x_n}]^\top$,
 $\Boldb = [\Boldb_{\Boldy}^\top,\Boldb_{\Boldx}^\top]^\top$.
For the majority of algorithms discussed in this article, $\Boldb$ is a binary vector with $b_{i} \in \{0,1\}$.
In this case, it is used to select certain measurements to be used ($b_i=1$) and others to be ignored ($b_i=0$) (see \cite{sunderhauf2012towards,sunderhauf2012switchable}).
When  $\Boldb$ is considered as a real variable with  $b_i \in [0,1]$,  $b_i$ can be looked upon as a mean to de-weight the $i$-th measurement, as will be discussed relative to eqn. (\ref{eqn:PosteriorInformation_b}).
%
Corresponding to  $\Boldb$, define binary matrix $\BoldPhi(\Boldb) = diag(\Boldb)$.


When  $\Boldb =\1$ (the vector of all ones), then eqn. (\ref{eqn:MAP_LS}) yields the same estimate as the solution of 
\begin{flalign} \label{eqn:P_one}
	\hat{\Boldx}_\Boldb & = \underset{\Boldx}{\text{argmin}} 
	\Big( \norm{\BoldSigma_{\BoldR}\BoldPhi(\Boldb_\Boldy)(\Boldy-\BoldH \Boldx)}_{2}^{2} \nonumber
	\\ &~~~~~~~~~~~~~~~~
	+ \norm{\BoldSigma_{\BoldP}\BoldPhi(\Boldb_{\Boldx})(\Boldx-\hat{\Boldx}^-)}_{2}^{2} \Big).
\end{flalign}
In the case, where some elements of $\Boldb$ are set to zero, the corresponding information is excluded from the optimization.
The matrix $\BoldPhi(\Boldb)$  has the effect of removing the ignored rows of either $\Boldy$ and $\BoldH$ or $\Boldx$ from the optimization.

Each choice of $\Boldb$ results in a different estimate $\hat{\Boldx}_\Boldb$. 
By defining:
\begin{equation} \label{eqn:measurement_Ab_cb}
\BoldA_{\Boldb} = \begin{bmatrix} 
	\BoldSigma_{\BoldR} \BoldPhi(\Boldb_{\Boldy})\BoldH \\ 
	\BoldSigma_{\BoldP} \BoldPhi(\Boldb_{\Boldx})	
	\end{bmatrix}, \ \
\Boldc_{\Boldb} = \begin{bmatrix} 
	\BoldSigma_{\BoldR} \BoldPhi(\Boldb_{\Boldy}) \Boldy \\ 
	\BoldSigma_{\BoldP} \BoldPhi(\Boldb_{\Boldx}) \hat{\Boldx}^- 	\end{bmatrix} 
\end{equation}
the cost function in eqn. ($\ref{eqn:P_one}$) can be written as:
\begin{equation} \label{eqn:Costfcn}
	C(\Boldx,\Boldb) = \norm{\BoldA_{\Boldb} \, \Boldx_k - \Boldc_{\Boldb}}^2
\end{equation}
which, for any given $\Boldb$, is the Least Squares problem that can be solved for $\Boldx$.
Minimizing the cost function in eqn. (\ref{eqn:Costfcn}) with respect to $\Boldx$ for a fixed $\Boldb$ yields:
\begin{eqnarray} \label{eqn:KF_info_msr_selected}
\hat{\Boldx}_\Boldb &=& 
	(\BoldA_\Boldb^{\top}\BoldA_\Boldb)^{-1} 	
			\BoldA_\Boldb^{\top}\Boldc_{\Boldb}  \label{eqn:Xleastsquares}\\ 
	&=& \left[ \BoldH^\top \BoldPhi(\Boldb_{\Boldy})^\top \BoldR^{-1} \BoldPhi(\Boldb_{\Boldy})\BoldH 
		+ \BoldPhi(\Boldb_{\Boldx})^\top\BoldP^{-1} \BoldPhi(\Boldb_{\Boldx}) \right]^{-1}  \nonumber  
	\\ &  & ~
	\left[ \BoldH^\top \BoldPhi(\Boldb_{\Boldy})^\top \BoldR^{-1} \BoldPhi(\Boldb_{\Boldy})\Boldy +  \BoldPhi(\Boldb_{\Boldx})^\top\BoldP^{-1} \BoldPhi(\Boldb_{\Boldx})\hat{\Boldx}^- \right].\nonumber
\end{eqnarray}
The posterior information matrix corresponding to the measurement selection vector $\Boldb$ is
\begin{flalign} \label{eqn:PosteriorInfoMatrix}
\BoldJ_{\Boldb}^+ = \BoldH^\top \BoldPhi(\Boldb_{\Boldy})^\top \BoldR^{-1}\BoldPhi(\Boldb_{\Boldy})\BoldH
		 +  \BoldPhi(\Boldb_{\Boldx})^\top\BoldP^{-1} \BoldPhi(\Boldb_{\Boldx}).
\end{flalign}


In the case where $\Boldb_\Boldx = \1$, using the form of $\BoldR$ discussed relative to Footnote \ref{ftnt:R_assumption}, the cost and posterior information can be expressed as\footnote{The notation $\norm{ \Boldv}_{\BoldP}^2=\Boldv^\top  	\BoldP^{-1} \Boldv=\norm{ \BoldSigma_\BoldP \, \Boldv }_2^2$ represents the Mahalanobis norm, which naturally arises with Gaussian distributions.}:
\begin{align}\label{eqn:cost_b}
	C( \Boldx,\Boldb) &= ~
	\norm{ \Boldx - \hat{\Boldx}^-}_{\BoldP}^2 
	+   \sum_{i=1}^{m} \frac{b_{y_i}^2}{\sigma_i^2} (\Boldh_i \Boldx- y_i)^2 
	\\
	\label{eqn:PosteriorInformation_b}
	\BoldJ_{\Boldb}^+  &= ~ 
	\sum_{i=1}^{m} \frac{b_{y_i}^2}{\sigma_i^2}  \, \Boldh_i^\top \Boldh_i 
		+  \BoldJ^-.
\end{align}	
This form is convenient for highlighting some inherent tradeoffs.
If $\Boldb_\Boldy = \0$, the solution is the prior and the cost function has value zero; however, no information is  extracted from the measurements so $\BoldJ_{\Boldb}^+  =  \BoldJ^-.$
For each $b_{y_i}$ that is switched from 0 to 1, both the cost and information matrix increase due to the new term in each summation.
The added cost of measurement $i$ is computed as a function of its residual $r_i =y_i - \Boldh_i \, \Boldx$.
When $\Boldb=\1$, the solution using all measurements is the same eqn. (\ref{eqn:KF_info}).
The goal in deciding which measurements to use is to achieve a good tradeoff between increased information  (quantified by the first term of $\BoldJ_{\Boldb}^+$) without high cost $C( \Boldx,\Boldb)$.


The approaches that treat $0 \le b_{y_i} \le 1$ as a real number allow an interesting alternative interpretation. 
Eqn. (\ref{eqn:cost_b})  could be derived from (\ref{eqn:MAP_LS}) by replacing $\BoldR$ with
$\BoldR_\Boldb = \sum_{i=1}^{m} \left(\frac{\sigma_i}{b_{y_i}}\right)^2  \Bolde_i  \,{\Bolde_i}^\top$.
When all $b_i=1$ it is the original problem using all measurements. 
Decreasing $b_i$ towards zero decreases the weighting of $y_i$ in the solution because its effective measurement noise standard deviation (i.e., $\frac{\sigma_i}{b_{y_i}}$) increases.
As 	$b_{y_i}$ approaches zero, $y_i$ is ignored.

%


